{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe8b278",
   "metadata": {},
   "source": [
    "# Batikku Product Based Capstone Project\n",
    "\n",
    "* **Source Data**:\n",
    "https://www.kaggle.com/datasets/dionisiusdh/indonesian-batik-motifs\n",
    "\n",
    "* **Reference**:\n",
    "https://medium.com/@cendekialnazalia/deep-learning-for-batik-classification-in-python-with-cnn-7bd3eb76f22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5a1767",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Import Library\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import Library\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten,Input\n",
    "from tensorflow.keras.optimizers.legacy import Adam,Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a21ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "sdir=r'C:\\Users\\HP\\0.Product Capstone Bangkit\\Indonesian_Batik_Motifs'\n",
    "\n",
    "\n",
    "filepaths=[]\n",
    "labels=[]\n",
    "classlist=os.listdir(sdir)\n",
    "for klass in classlist:\n",
    "    classpath=os.path.join(sdir,klass)\n",
    "    if os.path.isdir(classpath):\n",
    "        flist=os.listdir(classpath)\n",
    "        for f in flist:\n",
    "            fpath=os.path.join(classpath,f)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(klass)                   \n",
    "Fseries= pd.Series(filepaths, name='filepaths')\n",
    "Lseries=pd.Series(labels, name='labels')    \n",
    "df=pd.concat([Fseries, Lseries], axis=1)\n",
    "print (df.head())\n",
    "print (df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split=.8\n",
    "test_split=.1\n",
    "dummy_split=test_split/(1-train_split)\n",
    "train_df, dummy_df=train_test_split(df, train_size=train_split, shuffle=True, random_state=123)\n",
    "test_df, valid_df=train_test_split(dummy_df, train_size=dummy_split, shuffle=True, random_state=123)\n",
    "print ('train_df length: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "height=224\n",
    "width=224\n",
    "channels=3\n",
    "batch_size=64\n",
    "\n",
    "img_shape=(height, width, channels)\n",
    "img_size=(height, width)\n",
    "length=len(test_df)\n",
    "test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n",
    "test_steps=int(length/test_batch_size)\n",
    "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\n",
    "\n",
    "gen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    )\n",
    "train_gen=gen.flow_from_dataframe( train_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "validgen=ImageDataGenerator(rescale=1./255)\n",
    "valid_gen=validgen.flow_from_dataframe( valid_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "testgen=ImageDataGenerator(rescale=1./255)\n",
    "test_gen=testgen.flow_from_dataframe( test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "\n",
    "classes=list(train_gen.class_indices.keys())\n",
    "print (classes)\n",
    "class_count=len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_samples(gen):\n",
    "    test_dict=test_gen.class_indices\n",
    "    classes=list(test_dict.keys())    \n",
    "    images,labels=next(gen) # get a sample batch from the generator \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    length=len(labels)\n",
    "    if length<25:   #show maximum of 25 images\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    for i in range(r):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image=images[i]\n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color='blue', fontsize=16)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d38f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_samples(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=tf.keras.applications.Xception(include_top=False, weights=\"imagenet\",input_tensor=Input(shape=(224,224,3))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04235929",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Cendekia'\n",
    "print(\"Building model with\", base_model)\n",
    "model = tf.keras.Sequential([\n",
    "            # Note the input shape is the desired size of the image 128x128 with 3 bytes color\n",
    "            # This is the first convolution\n",
    "            base_model,\n",
    "            tf.keras.layers.Conv2D(filters=32, padding='same', kernel_size=3, activation='relu', strides=1),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "            tf.keras.layers.Dropout(rate=0.5),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(20, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.001), loss='categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc95f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a945e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(x=train_gen, epochs=100, validation_data=valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1101298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_in_color(txt_msg,fore_tupple,back_tupple,):\n",
    "    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n",
    "    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n",
    "    rf,gf,bf=fore_tupple\n",
    "    rb,gb,bb=back_tupple\n",
    "    msg='{0}' + txt_msg\n",
    "    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n",
    "    print(msg .format(mat), flush=True)\n",
    "    print('\\33[0m', flush=True) # returns default print color to back to black\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78356542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_plot(tr_data, start_epoch):\n",
    "    #Plot the training and validation data\n",
    "    tacc=tr_data.history['accuracy']\n",
    "    tloss=tr_data.history['loss']\n",
    "    vacc=tr_data.history['val_accuracy']\n",
    "    vloss=tr_data.history['val_loss']\n",
    "    Epoch_count=len(tacc)+ start_epoch\n",
    "    Epochs=[]\n",
    "    for i in range (start_epoch ,Epoch_count):\n",
    "        Epochs.append(i+1)   \n",
    "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
    "    val_lowest=vloss[index_loss]\n",
    "    index_acc=np.argmax(vacc)\n",
    "    acc_highest=vacc[index_acc]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
    "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
    "    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
    "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
    "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
    "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
    "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout\n",
    "    #plt.style.use('fivethirtyeight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cbb4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_plot(history,0)\n",
    "save_dir=r'./'\n",
    "subject='Batik Exception'\n",
    "acc=model.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\n",
    "msg=f'accuracy on the test set is {acc:5.2f} %'\n",
    "print_in_color(msg, (0,255,0),(55,65,80))\n",
    "save_id=str (model_name +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n",
    "save_loc=os.path.join(save_dir, save_id)\n",
    "model.save(save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info( test_gen, preds, print_code, save_dir, subject ):\n",
    "    class_dict=test_gen.class_indices\n",
    "    labels= test_gen.labels\n",
    "    file_names= test_gen.filenames \n",
    "    error_list=[]\n",
    "    true_class=[]\n",
    "    pred_class=[]\n",
    "    prob_list=[]\n",
    "    new_dict={}\n",
    "    error_indices=[]\n",
    "    y_pred=[]\n",
    "    for key,value in class_dict.items():\n",
    "        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n",
    "    # store new_dict as a text fine in the save_dir\n",
    "    classes=list(new_dict.values())     # list of string of class names\n",
    "    dict_as_text=str(new_dict)\n",
    "    dict_name= subject + '-' +str(len(classes)) +'.txt'  \n",
    "    dict_path=os.path.join(save_dir,dict_name)    \n",
    "    with open(dict_path, 'w') as x_file:\n",
    "        x_file.write(dict_as_text)    \n",
    "    errors=0      \n",
    "    for i, p in enumerate(preds):\n",
    "        pred_index=np.argmax(p)        \n",
    "        true_index=labels[i]  # labels are integer values\n",
    "        if pred_index != true_index: # a misclassification has occurred\n",
    "            error_list.append(file_names[i])\n",
    "            true_class.append(new_dict[true_index])\n",
    "            pred_class.append(new_dict[pred_index])\n",
    "            prob_list.append(p[pred_index])\n",
    "            error_indices.append(true_index)            \n",
    "            errors=errors + 1\n",
    "        y_pred.append(pred_index)    \n",
    "    if print_code !=0:\n",
    "        if errors>0:\n",
    "            if print_code>errors:\n",
    "                r=errors\n",
    "            else:\n",
    "                r=print_code           \n",
    "            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n",
    "            print_in_color(msg, (0,255,0),(55,65,80))\n",
    "            for i in range(r):                \n",
    "                split1=os.path.split(error_list[i])                \n",
    "                split2=os.path.split(split1[0])                \n",
    "                fname=split2[1] + '/' + split1[1]\n",
    "                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(fname, pred_class[i],true_class[i], ' ', prob_list[i])\n",
    "                print_in_color(msg, (255,255,255), (55,65,60))\n",
    "                #print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])               \n",
    "        else:\n",
    "            msg='With accuracy of 100 % there are no errors to print'\n",
    "            print_in_color(msg, (0,255,0),(55,65,80))\n",
    "    if errors>0:\n",
    "        plot_bar=[]\n",
    "        plot_class=[]\n",
    "        for  key, value in new_dict.items():        \n",
    "            count=error_indices.count(key) \n",
    "            if count!=0:\n",
    "                plot_bar.append(count) # list containg how many times a class c had an error\n",
    "                plot_class.append(value)   # stores the class \n",
    "        fig=plt.figure()\n",
    "        fig.set_figheight(len(plot_class)/3)\n",
    "        fig.set_figwidth(10)\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        for i in range(0, len(plot_class)):\n",
    "            c=plot_class[i]\n",
    "            x=plot_bar[i]\n",
    "            plt.barh(c, x, )\n",
    "            plt.title( ' Errors by Class on Test Set')\n",
    "    y_true= np.array(labels)        \n",
    "    y_pred=np.array(y_pred)\n",
    "    if len(classes)<= 30:\n",
    "        # create a confusion matrix \n",
    "        cm = confusion_matrix(y_true, y_pred )        \n",
    "        length=len(classes)\n",
    "        if length<8:\n",
    "            fig_width=8\n",
    "            fig_height=8\n",
    "        else:\n",
    "            fig_width= int(length * .5)\n",
    "            fig_height= int(length * .5)\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
    "        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n",
    "        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "    clr = classification_report(y_true, y_pred, target_names=classes)\n",
    "    print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_code=0\n",
    "preds=model.predict(test_gen) \n",
    "print_info( test_gen, preds, print_code, save_dir, subject ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5300c7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a781195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
